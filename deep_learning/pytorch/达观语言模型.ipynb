{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 达观数据竞赛（无预训练的词向量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import Path\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "warnings.filterwarnings(\"always\")\n",
    "\n",
    "PATH = Path(\"/home/liucc/data/new_data\")\n",
    "\n",
    "DATA_PATH = Path('/home/liucc/Workspace/NLP/da_guan_race/data_lm')\n",
    "DATA_PATH.mkdir(exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "\n",
    "def get_tokens(texts):\n",
    "    tok = [['_NEW_']+re.split(r'\\s+',t) for t in texts]\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(PATH/'train_set.csv')\n",
    "df_train.drop(columns = ['word_seg','id'], inplace = True)\n",
    "\n",
    "texts = df_train['article'].values\n",
    "labels = (df_train['class']-1).values\n",
    "\n",
    "toks = get_tokens(texts)\n",
    "print(len(toks))\n",
    "print(toks[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "freq = Counter(w for t in toks for w in t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13517\n"
     ]
    }
   ],
   "source": [
    "print(len(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common() if c>2]\n",
    "itos.insert(0,'_unk_') #未知字符\n",
    "itos.insert(0,'_pad_') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10158"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102277,)\n",
      "[250, 3, 377, 34, 27, 2, 245, 171, 4, 211, 452, 387, 27, 387, 28, 2, 47, 60, 221, 396, 6, 121, 42, 9, 3726, 4059, 5, 21, 249, 171, 305, 159, 672, 203, 7, 53, 17, 20, 6, 121, 2, 333, 284, 3163, 455, 245, 171, 211, 452, 4, 562, 510, 5, 81, 83, 2, 820, 315, 2589, 1096, 146, 100, 224, 507, 69, 241, 79, 507, 183, 302, 12, 6, 136, 237, 187, 325, 660, 2311, 1547, 588, 2, 447, 484, 1058, 253, 122, 688, 420, 758, 273, 4, 4354, 55, 520, 1868, 47, 532, 43, 40, 2]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "stoi = defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "\n",
    "ids = np.array([[stoi[c] for c in t] for t in toks])\n",
    "print(ids.shape)\n",
    "print(ids[0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# 序列化保存词汇表\n",
    "with open(DATA_PATH/'itos.pkl', 'wb') as f:\n",
    "    pickle.dump(itos, f)\n",
    "    \n",
    "with open(DATA_PATH/'stoi.pkl', 'wb') as f:\n",
    "    stoi_ = {k:v for k,v in stoi.items()}\n",
    "    pickle.dump(stoi_, f)\n",
    "    \n",
    "np.save(DATA_PATH/'ids.npy',ids)\n",
    "np.save(DATA_PATH/'labels.npy',labels)\n",
    "\n",
    "with open(DATA_PATH/'classes.pkl', 'wb') as f:\n",
    "    pickle.dump(set(labels), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总用量 278M\r\n",
      "-rw-r--r-- 1 liucc root 277M 9月   1 09:56 ids.npy\r\n",
      "-rw-r--r-- 1 liucc root   1M 9月   1 09:55 itos.pkl\r\n",
      "-rw-r--r-- 1 liucc root   1M 9月   1 09:56 labels.npy\r\n",
      "-rw-r--r-- 1 liucc root   1M 9月   1 09:55 stoi.pkl\r\n"
     ]
    }
   ],
   "source": [
    "% ls -l --block-size=M data_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反序列化读取词汇表\n",
    "with open(DATA_PATH/'itos.pkl', 'rb') as f:\n",
    "    itos = pickle.load(f)\n",
    "    \n",
    "with open(DATA_PATH/'stoi.pkl', 'rb') as f:\n",
    "    stoi_ = pickle.load(f)\n",
    "    stoi = defaultdict(lambda:0,{k:v for k,v in stoi_.items()})\n",
    "\n",
    "ids = np.load(DATA_PATH/'ids.npy')\n",
    "labels = np.load(DATA_PATH/'labels.npy')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将文字与标签匹配\n",
    "def get_paired_c2l(ids,labels):\n",
    "    if not len(ids)==len(labels):\n",
    "        raise RuntimeError('维度不匹配')\n",
    "    \n",
    "    cids = []\n",
    "    clabels = []\n",
    "    for t,l in zip(ids,labels):\n",
    "        cids += t\n",
    "        clabels += ([l]*len(t))\n",
    "    return np.array(cids),np.array(clabels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120492550\n",
      "[250   3 377  34  27   2 245 171   4 211 452 387  27 387  28   2  47  60 221 396]\n",
      "120492550\n",
      "[13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13]\n"
     ]
    }
   ],
   "source": [
    "cids,clabels = get_paired_c2l(ids,labels)\n",
    "print(len(cids))\n",
    "print(cids[:20])\n",
    "print(len(clabels))\n",
    "print(clabels[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(DATA_PATH/'cids.npy',cids)\n",
    "np.save(DATA_PATH/'clabels.npy',clabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立数据模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(object):\n",
    "    # x: length * words\n",
    "    # y: length \n",
    "    def __init__(self,x,y,bs,bptt):\n",
    "        super().__init__()\n",
    "        self.bs = bs\n",
    "        self.bptt = bptt\n",
    "        self.useGPU = False\n",
    "        self.batch_num = -1\n",
    "        \n",
    "        bl = np.size(x,0)//bs\n",
    "        \n",
    "        x = x[:bl*bs]\n",
    "        y = y[:bl*bs]\n",
    "        \n",
    "        xs = np.array([[x[i+j] for i in range(bl)] for j in range(0,len(x)-bl+1,bl)])\n",
    "        ys = np.array([[y[i+j] for i in range(bl)] for j in range(0,len(y)-bl+1,bl)])\n",
    "                \n",
    "        #截断成bs段再拼上\n",
    "        self.x = torch.LongTensor(xs).transpose(0,1) # length * batch_size\n",
    "        \n",
    "        self.y = torch.LongTensor(ys).transpose(0,1) # length * batch_size\n",
    "           \n",
    "    \n",
    "    def set_bptt(self,bptt):\n",
    "        self.bptt = bptt\n",
    "    \n",
    "    def cuda(self):\n",
    "        self.useGPU = True\n",
    "        \n",
    "        \n",
    "    def cpu(self):\n",
    "        self.useGPU = False\n",
    "        \n",
    "    def mini_batch(self,num):\n",
    "        self.batch_num = num\n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.batch_num if self.batch_num>0 else self.x.size(0)//self.bptt\n",
    "        \n",
    "    \n",
    "    #每次返回一行\n",
    "    def __iter__(self):\n",
    "        for i in range(0,self.x.size(0)-self.bptt+1,self.bptt):\n",
    "            if self.batch_num>0 and self.batch_num<=i//self.bptt:\n",
    "                break\n",
    "            else:\n",
    "                if self.useGPU:\n",
    "                    yield self.x[i:i+self.bptt,:].cuda(),self.y[i:i+self.bptt,:].cuda()\n",
    "                else:\n",
    "                    yield self.x[i:i+self.bptt,:],self.y[i:i+self.bptt,:]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1882696, 64])\n",
      "torch.Size([1882696, 64])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "cids = np.load(DATA_PATH/'cids.npy')\n",
    "clabels = np.load(DATA_PATH/'clabels.npy')\n",
    "\n",
    "bs,bptt = 64,10\n",
    "\n",
    "dm = CharModel(cids,clabels,bs,bptt)\n",
    "print(dm.x.shape)\n",
    "print(dm.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# 序列化保存词汇表\n",
    "with open(DATA_PATH/'dm.pkl', 'wb') as f:\n",
    "    pickle.dump(dm, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建LSTM网络进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import Path\n",
    "import pickle\n",
    "import collections\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH/'dm.pkl', 'rb') as f:\n",
    "    dm = pickle.load(f)\n",
    "\n",
    "with open(DATA_PATH/'classes.pkl', 'rb') as f:\n",
    "    classes = pickle.load(f)\n",
    "    \n",
    "with open(DATA_PATH/'itos.pkl', 'rb') as f:\n",
    "    itos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预训练的语言模型\n",
    "class LModelLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, class_size, em_sz, bs, nl, n_hidden):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl,self.class_size = vocab_size,nl,class_size\n",
    "        self.bs,self.n_hidden = bs,n_hidden\n",
    "        \n",
    "        self.e = nn.Embedding(vocab_size, em_sz)\n",
    "        self.rnn = nn.LSTM(em_sz, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, class_size)\n",
    "        self.init_hidden()\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs.size(1)\n",
    "        if bs!=self.bs:\n",
    "            self.bs = bs\n",
    "            self.init_hidden()\n",
    "        \n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = self.repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, bs, self.class_size)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        bs = self.bs\n",
    "        \n",
    "        if next(self.parameters()).is_cuda:\n",
    "            self.h = (Variable(torch.zeros(self.nl, bs, self.n_hidden)).cuda(),\n",
    "                  Variable(torch.zeros(self.nl, bs, self.n_hidden)).cuda())\n",
    "        else:\n",
    "            self.h = (Variable(torch.zeros(self.nl, bs, self.n_hidden)),\n",
    "                  Variable(torch.zeros(self.nl, bs, self.n_hidden)))     \n",
    "        \n",
    "    def repackage_var(self,h):\n",
    "        \"\"\"Wraps h in new Variables, to detach them from their history.\"\"\"\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            return tuple(self.repackage_var(v) for v in h) if type(h) == tuple else Variable(h.data).cuda()\n",
    "        else:\n",
    "            return tuple(self.repackage_var(v) for v in h) if type(h) == tuple else Variable(h.data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10158\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "em_sz,n_hidden,nl = 200,512,2\n",
    "vocab_size = len(itos)\n",
    "class_size = len(classes)\n",
    "\n",
    "print(vocab_size)\n",
    "print(class_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LModelLSTM(vocab_size,class_size, em_sz, bs, nl, n_hidden)\n",
    "opt_fn = torch.optim.Adam(m.parameters(),lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(model,data_train,data_val,opt,loss_f,epoch,useGPU=True):\n",
    "    \n",
    "    if useGPU and torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        data_train.cuda()\n",
    "        print(f'epoch  train_loss  train_acc')        \n",
    "    \n",
    "    for i in range(epoch):\n",
    "        \n",
    "        loss_train = []\n",
    "        model.train()\n",
    "        \n",
    "        true_ls = []\n",
    "        pred_ls = []\n",
    "        #true_y: batch_size\n",
    "        model.init_hidden()\n",
    "        \n",
    "        stime = time.time()\n",
    "        bind = 0\n",
    "        tind = len(data_train)\n",
    "        for x,y in data_train:\n",
    "            \n",
    "            model.zero_grad()\n",
    "\n",
    "            pred_y = model(Variable(x)) #bptt*batch*classes\n",
    "            \n",
    "            pred_y = pred_y.view(-1,pred_y.size(-1))\n",
    "            true_y = y.view(-1)\n",
    "            \n",
    "            _,pred_l = pred_y.max(1)\n",
    "            pred_ls.append(pred_l.data.cpu().numpy())\n",
    "            true_ls.append(true_y.cpu().numpy())\n",
    "\n",
    "            loss = loss_f(pred_y,Variable(true_y))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            closs = loss.data.cpu().numpy()\n",
    "            loss_train.append(closs)\n",
    "        \n",
    "            ctime = time.time()\n",
    "            ptime = (ctime-stime)/60\n",
    "            bind+=1\n",
    "            rtime = ptime*(tind-bind)/bind\n",
    "            print(f'\\rProgress: {ptime:.2f}<{rtime:.2f}  loss:{float(closs):.4f}',end=\"\")\n",
    "\n",
    "        loss_train = np.mean(np.array(loss_train))\n",
    "        \n",
    "        true_ls = np.concatenate(true_ls,axis=0)\n",
    "        pred_ls = np.concatenate(pred_ls,axis=0)\n",
    "        acc_train = (true_ls==pred_ls).sum()/np.size(true_ls,0)\n",
    "\n",
    "\n",
    "\n",
    "        print(f'\\r{i:5}  {loss_train:10.4f}  {acc_train:9.4f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  train_loss  train_acc\n",
      "    0      0.5893     0.8238.359199970960617076\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dm.mini_batch(-1)\n",
    "opt_fn = torch.optim.Adam(m.parameters(),lr=0.0001)\n",
    "train(m,dm,None,opt_fn,nn.NLLLoss(),1, useGPU=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liucc/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type LModelLSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(m,DATA_PATH/'char_model_pbtt10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load(DATA_PATH/'char_model_pbtt10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  train_loss  train_acc\n",
      "    0      0.7475     0.7788.62251842021942146\n"
     ]
    }
   ],
   "source": [
    "dm.mini_batch(-1)\n",
    "dm.set_bptt(20)\n",
    "opt_fn = torch.optim.Adam(m.parameters(),lr=0.0001)\n",
    "train(m,dm,None,opt_fn,nn.NLLLoss(),1, useGPU=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liucc/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type LModelLSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(m,DATA_PATH/'char_model_pbtt20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load(DATA_PATH/'char_model_pbtt20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  train_loss  train_acc\n",
      "    0      0.8368     0.7522.80672907829284677\n",
      "    1      0.7547     0.7737.69244801998138436\n",
      "    2      0.6979     0.7905.63341861963272126\n",
      "    3      0.6467     0.8051.56036633253097536\n",
      "    4      0.5993     0.8192.57578408718109135\n",
      "    5      0.5465     0.8339.40625992417335516\n",
      "    6      0.4974     0.8486.37763863801956177\n",
      "    7      0.4484     0.8626.31454861164093023\n",
      "    8      0.3999     0.8773.27238628268241884\n",
      "    9      0.3597     0.8895.34817832708358765\n",
      "   10      0.3192     0.9016.283030599355697636\n",
      "   11      0.2845     0.9120.220218718051910475\n",
      "   12      0.2551     0.9209.399712592363357545\n",
      "   13      0.2230     0.9298.166752323508262635\n",
      "   14      0.2020     0.9367.145413517951965335\n"
     ]
    }
   ],
   "source": [
    "dm.mini_batch(-1)\n",
    "dm.set_bptt(50)\n",
    "opt_fn = torch.optim.Adam(m.parameters(),lr=0.0001)\n",
    "train(m,dm,None,opt_fn,nn.NLLLoss(),15, useGPU=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liucc/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type LModelLSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(m,DATA_PATH/'char_model_pbtt50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load(DATA_PATH/'char_model_pbtt50',map_location=lambda storage,loc:storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import pickle\n",
    "\n",
    "# 反序列化读取词汇表\n",
    "with open(DATA_PATH/'itos.pkl', 'rb') as f:\n",
    "    itos = pickle.load(f)\n",
    "    \n",
    "with open(DATA_PATH/'stoi.pkl', 'rb') as f:\n",
    "    stoi_ = pickle.load(f)\n",
    "    stoi = defaultdict(lambda:0,{k:v for k,v in stoi_.items()})\n",
    "\n",
    "ids = np.load(DATA_PATH/'ids.npy')\n",
    "labels = np.load(DATA_PATH/'labels.npy')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.9\n",
    "VAL_RATIO = 0.1\n",
    "\n",
    "ids = np.array([np.array(i) for i in ids])\n",
    "\n",
    "rid = np.random.permutation(len(ids))\n",
    "ids = ids[rid]\n",
    "labels = labels[rid]\n",
    "\n",
    "trn_num = math.floor(len(ids)*TRAIN_RATIO)\n",
    "val_num = math.floor(len(ids)*VAL_RATIO)\n",
    "\n",
    "trn_ids = ids[:trn_num]\n",
    "trn_label = labels[:trn_num]\n",
    "val_ids = ids[-val_num:]\n",
    "val_label = labels[-val_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchItem(object):\n",
    "    #end_inds: 结束的列id\n",
    "    #sqz_inds: 消失的列id\n",
    "    def __init__(self,xs,ys,ids,end_ids=None,sqz_ids=None,useGPU=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.xs = torch.from_numpy(np.stack(xs,axis=1)).type(torch.LongTensor)\n",
    "        self.ys = torch.from_numpy(np.stack(ys,axis=1)).type(torch.LongTensor)\n",
    "        self.ids = ids\n",
    "        self.end_ids = torch.LongTensor(end_ids) if end_ids is not None else torch.LongTensor([])\n",
    "        self.sqz_ids = torch.LongTensor(sqz_ids) if sqz_ids is not None else torch.LongTensor([])\n",
    "        \n",
    "        if useGPU:\n",
    "            self.xs = self.xs.cuda()\n",
    "            self.ys = self.ys.cuda()\n",
    "            self.end_ids = self.end_ids.cuda()\n",
    "            self.sqz_ids = self.sqz_ids.cuda()\n",
    "\n",
    "class DocItem(object):\n",
    "    # x: length\n",
    "    # y: number\n",
    "    def __init__(self,x,y,index,bptt,pad_id):\n",
    "        super().__init__()\n",
    "        self.x = np.array(x)\n",
    "        self.y = y\n",
    "        self.index = index #文章序号\n",
    "        self.bptt = bptt\n",
    "        self.pad_id = pad_id\n",
    "                \n",
    "        self.cur_i = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.cur_i = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.floor(len(self.x)/self.bptt)\n",
    "    \n",
    "    def has_next(self):\n",
    "        return True if self.cur_i<self.__len__() else False\n",
    "\n",
    "    def next_batch(self):\n",
    "        \n",
    "        if self.has_next():\n",
    "            lens = len(self.x)\n",
    "            i = self.cur_i*self.bptt\n",
    "            self.cur_i += 1\n",
    "            \n",
    "            if i+self.bptt>lens:\n",
    "                x_b = np.concatenate((self.x[i:],np.ones(i+self.bptt-lens)*self.pad_id))\n",
    "            else:\n",
    "                x_b = self.x[i:i+self.bptt]\n",
    "            \n",
    "            y_b = np.ones(len(x_b))*self.y\n",
    "            \n",
    "            return x_b,y_b,self.index\n",
    "                \n",
    "        \n",
    "    \n",
    "class DocModel(object):\n",
    "    # x: length * words list\n",
    "    # y: length  list\n",
    "    def __init__(self,x,y,bs,bptt,pad_id):\n",
    "        super().__init__()\n",
    "        self.pad_id = pad_id\n",
    "        self.bptt = bptt\n",
    "        self.bs = bs\n",
    "        self.useGPU = False\n",
    "        self.doc_num = -1\n",
    "                       \n",
    "        #截断成bs段再拼上\n",
    "        self.x = x # length * batch_size\n",
    "        self.y = y if y is not None else [-1]*len(x) # length\n",
    "        \n",
    "        self.cur_ind = 0\n",
    "           \n",
    "    def get_curid(self):\n",
    "        return self.cur_ind\n",
    "    \n",
    "    def set_bptt(self,bptt):\n",
    "        self.bptt = bptt\n",
    "    \n",
    "    def cuda(self):\n",
    "        self.useGPU = True\n",
    "        \n",
    "        \n",
    "    def cpu(self):\n",
    "        self.useGPU = False\n",
    "        \n",
    "    def mini_num(self,num):\n",
    "        self.doc_num = num\n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.doc_num if self.doc_num>0 else len(self.x)\n",
    "        \n",
    "    def get_doc(self,i):\n",
    "        return DocItem(self.x[i],self.y[i],i,self.bptt,self.pad_id)\n",
    "    \n",
    "    def get_batch(self,ctner,end_ids,sqz_ids):\n",
    "        xs,ys,ids = [],[],[]\n",
    "        for c in ctner:\n",
    "            if c is not None:\n",
    "                bx,by,bid = c.next_batch()\n",
    "                xs.append(bx)\n",
    "                ys.append(by)\n",
    "                ids.append(bid)\n",
    "                \n",
    "        return BatchItem(xs,ys,ids,end_ids,sqz_ids,self.useGPU)\n",
    "    \n",
    "    #每次返回一行\n",
    "    def __iter__(self):\n",
    "        self.cur_ind = 0\n",
    "        lens = self.doc_num if self.doc_num>0 else len(self.y)\n",
    "        \n",
    "        ctner = []\n",
    "        batch_1 = min(self.bs,lens)\n",
    "        for i in range(batch_1):\n",
    "            ctner.append(self.get_doc(i))\n",
    "        \n",
    "        ctner = np.array(ctner)\n",
    "        self.cur_ind = batch_1\n",
    "        \n",
    "        go_on = True\n",
    "        \n",
    "        while go_on:\n",
    "            #判断是否有文章已结束\n",
    "            end_ids = [i for i,c in enumerate(ctner) if not c.has_next()]\n",
    "            ctner[end_ids] = None   \n",
    "            \n",
    "            #填入新的文章\n",
    "            for e_id in end_ids:\n",
    "                if self.cur_ind>=lens:\n",
    "                    break\n",
    "                ctner[e_id] = self.get_doc(self.cur_ind)\n",
    "                self.cur_ind += 1\n",
    "                \n",
    "            sqz_ids = [i for i,c in enumerate(ctner) if c is None]    \n",
    "            \n",
    "            #生成batch对象\n",
    "            if len(sqz_ids)<len(ctner):\n",
    "                ctner = np.array([c for c in ctner if c is not None])\n",
    "                yield self.get_batch(ctner,end_ids,sqz_ids)\n",
    "            else:\n",
    "                go_on = False\n",
    "        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,bs = 50,64\n",
    "trn_dm = DocModel(trn_ids,trn_label,bs,bptt,stoi['_pad_'])\n",
    "val_dm = DocModel(val_ids,val_label,bs,bptt,stoi['_pad_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "trn_dm.mini_num(200)\n",
    "doc_re = {}\n",
    "doci_re = {}\n",
    "for item in trn_dm:\n",
    "    for i,did in enumerate(item.ids):\n",
    "        if did not in doc_re.keys():\n",
    "            doc_re[did]=[]\n",
    "            doci_re[did] = int(item.ys[:,i][0])\n",
    "            \n",
    "        doc_re[did]+= [int(c) for c in item.xs[:,i] if int(c)>0]\n",
    "    \n",
    "for i in doc_re:\n",
    "    o_text = [int(c) for c in trn_ids[i] if int(c)>0]\n",
    "    o_text = o_text[:len(doc_re[i])]\n",
    "    print(o_text==doc_re[i],doci_re[i]==trn_label[i])\n",
    "    \n",
    "trn_dm.mini_num(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClasLSTM(nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl,self.class_size = m.vocab_size,m.nl,m.class_size\n",
    "        self.n_hidden = m.n_hidden\n",
    "        self.bs = m.bs\n",
    "        self.bs_old = m.bs\n",
    "        \n",
    "        self.e = nn.Embedding(m.e.weight.data.size(0), m.e.weight.data.size(1))\n",
    "        self.rnn = nn.LSTM(m.e.weight.data.size(1), self.n_hidden, self.nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(self.n_hidden, self.class_size)\n",
    "        \n",
    "        self.e.weight.data.copy_(m.e.weight.data)\n",
    "        for w1,w2 in zip(self.rnn.parameters(),m.rnn.parameters()):\n",
    "            w1.data.copy_(w2.data)\n",
    "            \n",
    "        self.l_out.weight.data.copy_(m.l_out.weight.data)\n",
    "              \n",
    "        \n",
    "        self.init_hidden()\n",
    "        \n",
    "    def restore(self):\n",
    "        self.bs = self.bs_old\n",
    "        \n",
    "    def forward(self, cs, end_ids, sqz_ids):\n",
    "        self.h = self.change_hidden(end_ids,sqz_ids)\n",
    "        if self.bs!=cs.size(1):\n",
    "            print(f'batch size is different self.bs:{self.bs} x.bs:{cs.size(1)}!')\n",
    "            self.bs = cs.size(1)\n",
    "            self.init_hidden()\n",
    "        \n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        #self.h = self.repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.bs, self.class_size)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \n",
    "        if next(self.parameters()).is_cuda:\n",
    "            self.h = (Variable(torch.zeros(self.nl, self.bs, self.n_hidden)).cuda(),\n",
    "                  Variable(torch.zeros(self.nl, self.bs, self.n_hidden)).cuda())\n",
    "        else:\n",
    "            self.h = (Variable(torch.zeros(self.nl, self.bs, self.n_hidden)),\n",
    "                  Variable(torch.zeros(self.nl, self.bs, self.n_hidden)))     \n",
    "            \n",
    "    def change_hidden(self,end_ids,sqz_ids):\n",
    "        \n",
    "        end_ids = end_ids.cpu()\n",
    "        sqz_ids = sqz_ids.cpu()\n",
    "        \n",
    "        h0 = torch.zeros_like(self.h[0].data.cpu())\n",
    "        h1 = torch.zeros_like(self.h[1].data.cpu())\n",
    "        \n",
    "        h0.copy_(self.h[0].data.cpu())\n",
    "        h1.copy_(self.h[1].data.cpu())\n",
    "        if len(end_ids)>0:\n",
    "            h0[:,end_ids,:] = 0\n",
    "            h1[:,end_ids,:] = 0\n",
    "            \n",
    "                \n",
    "        if len(sqz_ids)>0:\n",
    "            left_ids = [i for i in range(h0.size(1)) if i not in set(sqz_ids)]\n",
    "            h0 = h0[:,left_ids,:].contiguous()\n",
    "            h1 = h1[:,left_ids,:].contiguous()\n",
    "            \n",
    "            self.bs -= len(sqz_ids)\n",
    "            \n",
    "        if next(self.parameters()).is_cuda:\n",
    "            return (Variable(h0).cuda(),Variable(h1).cuda())\n",
    "        else:\n",
    "            return (Variable(h0),Variable(h1))    \n",
    "            \n",
    "                   \n",
    "    def repackage_var(self,h):\n",
    "        \"\"\"Wraps h in new Variables, to detach them from their history.\"\"\"\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            return tuple(self.repackage_var(v) for v in h) if type(h) == tuple else Variable(h.data).cuda()\n",
    "        else:\n",
    "            return tuple(self.repackage_var(v) for v in h) if type(h) == tuple else Variable(h.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_cm(model,data_train,data_val,opt,loss_f,epoch,useGPU=True):\n",
    "    \n",
    "    if useGPU and torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        data_train.cuda()\n",
    "        if not data_val is None:\n",
    "            data_val.cuda()\n",
    "            print(f'epoch  train_loss  val_loss  train_acc  val_acc')\n",
    "        \n",
    "        else:\n",
    "            print(f'epoch  train_loss  train_acc')        \n",
    "    \n",
    "    \n",
    "    for i in range(epoch):\n",
    "        \n",
    "        ep_result = step_cm(model,data_train,opt,loss_f,True)\n",
    "                \n",
    "        acc_train = ep_result['ep_acc']\n",
    "        loss_train = np.mean(np.array(ep_result['ep_loss']))\n",
    "            \n",
    "        \n",
    "        if data_val is not None:\n",
    "            ep_result = step_cm(model,data_val,opt,loss_f,False)\n",
    "                        \n",
    "            acc_val = ep_result['ep_acc']\n",
    "            loss_val = np.mean(np.array(ep_result['ep_loss']))\n",
    "                \n",
    "            print(f'\\r{i:5}  {loss_train:10.4f}  {loss_val:8.4f}  {acc_train:9.4f}  {acc_val:7.4f}')\n",
    "            \n",
    "        else:\n",
    "            print(f'\\r{i:5}  {loss_train:10.4f}  {acc_train:9.4f}')\n",
    "            \n",
    "    \n",
    "\n",
    "def step_cm(model,data,opt=None,loss_f=None,train=True):\n",
    "    model.restore()\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "      \n",
    "        \n",
    "    stime = time.time()\n",
    "    bind = 0\n",
    "    tind = len(data) #文章总数\n",
    "    model.init_hidden()\n",
    "\n",
    "    result_epoch = {}\n",
    "    ep_pred_y = {} #per doc\n",
    "    ep_true_y = {}\n",
    "    ep_pred_dis = {}\n",
    "    \n",
    "    ep_loss = []\n",
    "    ep_acc = 0\n",
    "    for item in data:\n",
    "        \n",
    "                        \n",
    "        assert item.xs.shape==item.ys.shape, f'x,y 维度不匹配. x:{item.xs.shape} y:{item.ys.shape}'\n",
    "\n",
    "        if train:\n",
    "            model.zero_grad()\n",
    "\n",
    "        pred_y = model(Variable(item.xs),item.end_ids,item.sqz_ids) #bptt*batch_size*classes\n",
    "\n",
    "        true_y = item.ys\n",
    "\n",
    "        _,pred_l = pred_y.max(2)\n",
    "\n",
    "        pred_l = pred_l.data.cpu().numpy() #bptt*batch_size\n",
    "        true_l = true_y.cpu().numpy()\n",
    "\n",
    "        rt_num = (pred_l==true_l).sum()\n",
    "        tt_num = pred_l.size\n",
    "        ct_acc = rt_num/tt_num\n",
    "        \n",
    "        ep_acc = 0.99*ep_acc+0.01*ct_acc if ep_acc>0 else ct_acc\n",
    "\n",
    "        if loss_f is not None:\n",
    "            loss = loss_f(pred_y.view(-1,pred_y.size(-1)),Variable(true_y.view(-1)))\n",
    "            closs = loss.data.cpu().numpy()\n",
    "            ep_loss.append(closs)\n",
    "        \n",
    "        if train:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        \n",
    "\n",
    "        ctime = time.time()\n",
    "        ptime = (ctime-stime)/60\n",
    "        bind = data.get_curid()\n",
    "        rtime = ptime*(tind-bind)/bind\n",
    "        print(f'\\rProgress: {ptime:.2f}<{rtime:.2f}  loss:{float(closs):.4f}',end=\"\")\n",
    "    \n",
    "    \n",
    "    return {'ep_loss':ep_loss,'ep_acc':ep_acc}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "m = torch.load(DATA_PATH/'char_model_pbtt50',map_location=lambda storage,loc:storage)\n",
    "cm = ClasLSTM(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  train_loss  val_loss  train_acc  val_acc\n",
      "    0      1.6918    9.5757     0.9401   0.6755\n",
      "    1      1.6288    9.8589     0.9476   0.6746\n",
      "    2      1.5848   10.8773     0.9524   0.6705\n"
     ]
    }
   ],
   "source": [
    "trn_dm.mini_num(-1)\n",
    "val_dm.mini_num(-1)\n",
    "opt_fn = torch.optim.Adam(cm.parameters(),lr=0.0001)\n",
    "train_cm(cm,trn_dm,val_dm,opt_fn,nn.NLLLoss(),1, useGPU=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liucc/anaconda3/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type ClasLSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(cm,DATA_PATH/'classify_model_pbtt50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = torch.load(DATA_PATH/'classify_model_pbtt50',map_location=lambda storage,loc:storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# 反序列化读取词汇表\n",
    "with open(DATA_PATH/'itos.pkl', 'rb') as f:\n",
    "    itos = pickle.load(f)\n",
    "    \n",
    "with open(DATA_PATH/'stoi.pkl', 'rb') as f:\n",
    "    stoi_ = pickle.load(f)\n",
    "    stoi = defaultdict(lambda:0,{k:v for k,v in stoi_.items()})\n",
    "\n",
    "df_test = pd.read_csv(PATH/'test_set.csv')\n",
    "df_test.drop(columns = ['word_seg','id'], inplace = True)\n",
    "\n",
    "texts_t = df_test['article'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_t = get_tokens(texts_t)\n",
    "ids_t = np.array([[stoi[c] for c in t] for t in toks_t])\n",
    "\n",
    "np.save(DATA_PATH/'ids_test.npy',ids_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_t = np.load(DATA_PATH/'ids_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,bs = 50,64\n",
    "tst_dm = DocModel(ids_t,None,bs,bptt,stoi['_pad_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "def predict_cm(model,data,useGPU=True):\n",
    "    \n",
    "    if useGPU and torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        data.cuda()\n",
    "        \n",
    "    model.eval()\n",
    "        \n",
    "    \n",
    "    return avg_one(model,data)\n",
    "    \n",
    "def avg_one(model,data):\n",
    "     \n",
    "    stime = time.time()\n",
    "    bind = 0\n",
    "    tind = len(data) #文章总数\n",
    "    model.init_hidden()\n",
    "\n",
    "    res = dict()\n",
    "    for item in data:\n",
    "                            \n",
    "        \n",
    "        pred_y = model(Variable(item.xs),item.end_ids,item.sqz_ids) #bptt*batch_size*classes\n",
    "\n",
    "        _,pred_l = pred_y.max(2)\n",
    "\n",
    "        pred_l = pred_l.data.cpu().numpy()[-1,:] #batch_size\n",
    "        \n",
    "        for i,doc_id in enumerate(item.ids):\n",
    "            if doc_id not in res.keys():\n",
    "                res[doc_id] = [pred_l[i]]\n",
    "            else:\n",
    "                res[doc_id].append(pred_l[i])\n",
    "        \n",
    "        ctime = time.time()\n",
    "        ptime = (ctime-stime)/60\n",
    "        bind = data.get_curid()\n",
    "        rtime = ptime*(tind-bind)/bind\n",
    "        print(f'\\rProgress: {ptime:.2f}<{rtime:.2f}',end=\"\")\n",
    "    \n",
    "    pred_ys = []\n",
    "    for doc_id in range(len(res)):\n",
    "        c = Counter(res[doc_id]).most_common(1)[0][0]\n",
    "        pred_ys.append(c)\n",
    "    \n",
    "    return pred_ys\n",
    "\n",
    "def last(model,data):\n",
    "     \n",
    "    stime = time.time()\n",
    "    bind = 0\n",
    "    tind = len(data) #文章总数\n",
    "    model.init_hidden()\n",
    "\n",
    "    res = dict()\n",
    "    for item in data:\n",
    "                            \n",
    "        \n",
    "        pred_y = model(Variable(item.xs),item.end_ids,item.sqz_ids) #bptt*batch_size*classes\n",
    "\n",
    "        _,pred_l = pred_y.max(2)\n",
    "\n",
    "        pred_l = pred_l.data.cpu().numpy()[-1,:] #batch_size\n",
    "        \n",
    "        for i,doc_id in enumerate(item.ids):\n",
    "            res[doc_id] = pred_l[i]\n",
    "        \n",
    "        ctime = time.time()\n",
    "        ptime = (ctime-stime)/60\n",
    "        bind = data.get_curid()\n",
    "        rtime = ptime*(tind-bind)/bind\n",
    "        print(f'\\rProgress: {ptime:.2f}<{rtime:.2f}',end=\"\")\n",
    "    \n",
    "    pred_ys = []\n",
    "    for doc_id in range(len(res)):\n",
    "        pred_ys.append(res[doc_id])\n",
    "    \n",
    "    return pred_ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size is different self.bs:1 x.bs:64!\n",
      "Progress: 5.13<0.00"
     ]
    }
   ],
   "source": [
    "pred_ys = predict_cm(cm,tst_dm,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.49      0.58       250\n",
      "          1       0.87      0.71      0.78       143\n",
      "          2       0.94      0.82      0.87       390\n",
      "          3       0.89      0.88      0.88       168\n",
      "          4       0.75      0.91      0.82       109\n",
      "          5       0.94      0.85      0.89       317\n",
      "          6       0.80      0.75      0.77       162\n",
      "          7       0.65      0.86      0.74       356\n",
      "          8       0.97      0.87      0.92       387\n",
      "          9       0.85      0.70      0.77       243\n",
      "         10       0.66      0.80      0.72       187\n",
      "         11       0.80      0.63      0.70       276\n",
      "         12       0.75      0.80      0.77       383\n",
      "         13       0.76      0.83      0.79       323\n",
      "         14       0.89      0.93      0.91       381\n",
      "         15       0.84      0.23      0.36       138\n",
      "         16       0.82      0.79      0.80       155\n",
      "         17       0.83      0.90      0.86       395\n",
      "         18       0.46      0.76      0.57       237\n",
      "\n",
      "avg / total       0.81      0.79      0.78      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(trn_dm.y[:5000], pred_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame({'class':pred_ys})\n",
    "df_result['class'] = df_result['class']+1\n",
    "df_result.to_csv(DATA_PATH/'result_char.csv',index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102277"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
